{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c8630-750c-44a0-bf55-1352feef8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cf15c8-af79-42a2-aa5a-ee10d75effaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# os.environ['MUJOCO_GL'] = 'egl' # if no display\n",
    "os.environ['MUJOCO_GL'] = 'glfw'\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "import exploration as expl\n",
    "import models\n",
    "import tools\n",
    "import wrappers\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions as torchd\n",
    "to_np = lambda x: x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a921bf-7b75-41fe-ada7-5aa5b6962f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_type(default):\n",
    "  def parse_string(x):\n",
    "    if default is None:\n",
    "      return x\n",
    "    if isinstance(default, bool):\n",
    "      return bool(['False', 'True'].index(x))\n",
    "    if isinstance(default, int):\n",
    "      return float(x) if ('e' in x or '.' in x) else int(x)\n",
    "    if isinstance(default, (list, tuple)):\n",
    "      return tuple(args_type(default[0])(y) for y in x.split(','))\n",
    "    return type(default)(x)\n",
    "  def parse_object(x):\n",
    "    if isinstance(default, (list, tuple)):\n",
    "      return tuple(x)\n",
    "    return x\n",
    "  return lambda x: parse_string(x) if isinstance(x, str) else parse_object(x)\n",
    "\n",
    "config = argparse.Namespace(act='ELU', action_repeat=2, actor_disc=5, actor_dist='trunc_normal', actor_entropy='1e-4', actor_grad_clip=100, actor_init_std=1.0, actor_layers=4, actor_lr=8e-05, actor_min_std=0.1, actor_outscale=0.0, actor_state_entropy=0.0, actor_temp=0.1, batch_length=50, batch_size=50, behavior_stop_grad=True, clip_rewards='identity', cnn_depth=32, collect_dyn_sample=True, dataset_size=0, debug=False, decoder_kernels=(5, 5, 6, 6), decoder_thin=True, device='cuda:0', disag_action_cond=False, disag_layers=4, disag_log=True, disag_models=10, disag_offset=1, disag_target='stoch', disag_units=400, discount=0.99, discount_lambda=0.95, discount_layers=3, discount_scale=1.0, dyn_cell='gru', dyn_deter=200, dyn_discrete=0, dyn_hidden=200, dyn_input_layers=1, dyn_mean_act='none', dyn_min_std=0.1, dyn_output_layers=1, dyn_rec_depth=1, dyn_shared=False, dyn_std_act='sigmoid2', dyn_stoch=50, dyn_temp_post=True, encoder_kernels=(4, 4, 4, 4), envs=1, eval_every=10000.0, eval_noise=0.0, eval_state_mean=False, evaldir=None, expl_amount=0.0, expl_behavior='greedy', expl_extr_scale=0.0, expl_gifs=False, expl_intr_scale=1.0, expl_until=0, future_entropy=False, grad_clip=100, grad_heads=('image', 'reward'), grayscale=False, imag_gradient='dynamics', imag_gradient_mix='0.1', imag_horizon=15, imag_sample=True, kl_balance='0.8', kl_forward=False, kl_free='1.0', kl_scale='1.0', log_every=10000.0, logdir=None, model_lr=0.0003, offline_evaldir='', offline_traindir='', opt='adam', opt_eps=1e-05, oversample_ends=False, precision=16, pred_discount=False, prefill=2500, pretrain=100, reset_every=0, reward_layers=2, reward_scale=1.0, seed=0, size=(64, 64), slow_actor_target=True, slow_target_fraction=1, slow_target_update=100, slow_value_target=True, steps=10000000.0, task='dmc_walker_walk', time_limit=1000, train_every=5, train_steps=1, traindir=None, units=400, value_decay=0.0, value_grad_clip=100, value_head='normal', value_layers=3, value_lr=8e-05, weight_decay=0.0)\n",
    "\n",
    "config.logdir = 'trial'\n",
    "config.eval_every = 5e3\n",
    "config.log_every = 5e3\n",
    "config.steps = 1e5 \n",
    "config.device = 'cuda:0'\n",
    "logdir = pathlib.Path(config.logdir).expanduser()\n",
    "config.traindir = config.traindir or logdir / 'train_eps'\n",
    "config.evaldir = config.evaldir or logdir / 'eval_eps'\n",
    "config.steps //= config.action_repeat\n",
    "config.eval_every //= config.action_repeat\n",
    "config.log_every //= config.action_repeat\n",
    "config.time_limit //= config.action_repeat\n",
    "config.act = getattr(torch.nn, config.act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fd0f95-2857-4e93-8192-53b024b98b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_steps(folder):\n",
    "  return sum(int(str(n).split('-')[-1][:-4]) - 1 for n in folder.glob('*.npz'))\n",
    "\n",
    "logdir.mkdir(parents=True, exist_ok=True)\n",
    "config.traindir.mkdir(parents=True, exist_ok=True)\n",
    "config.evaldir.mkdir(parents=True, exist_ok=True)\n",
    "step = count_steps(config.traindir)\n",
    "logger = tools.Logger(logdir, config.action_repeat * step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbce97dd-ff06-4aa8-a8c9-9056a344cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "if config.offline_traindir:\n",
    "    directory = config.offline_traindir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.traindir\n",
    "train_eps = tools.load_episodes(directory, limit=config.dataset_size)\n",
    "if config.offline_evaldir:\n",
    "    directory = config.offline_evaldir.format(**vars(config))\n",
    "else:\n",
    "    directory = config.evaldir\n",
    "eval_eps = tools.load_episodes(directory, limit=1)\n",
    "\n",
    "def make_dataset(episodes, config):\n",
    "  generator = tools.sample_episodes(\n",
    "      episodes, config.batch_length, config.oversample_ends)\n",
    "  dataset = tools.from_generator(generator, config.batch_size)\n",
    "  return dataset\n",
    "train_dataset = make_dataset(train_eps, config)\n",
    "\n",
    "def process_episode(config, logger, mode, train_eps, eval_eps, episode):\n",
    "  directory = dict(train=config.traindir, eval=config.evaldir)[mode]\n",
    "  cache = dict(train=train_eps, eval=eval_eps)[mode]\n",
    "  filename = tools.save_episodes(directory, [episode])[0]\n",
    "  length = len(episode['reward']) - 1\n",
    "  score = float(episode['reward'].astype(np.float64).sum())\n",
    "  video = episode['image']\n",
    "  if mode == 'eval':\n",
    "    cache.clear()\n",
    "  if mode == 'train' and config.dataset_size:\n",
    "    total = 0\n",
    "    for key, ep in reversed(sorted(cache.items(), key=lambda x: x[0])):\n",
    "      if total <= config.dataset_size - length:\n",
    "        total += len(ep['reward']) - 1\n",
    "      else:\n",
    "        del cache[key]\n",
    "    logger.scalar('dataset_size', total + length)\n",
    "  cache[str(filename)] = episode\n",
    "  print(f'{mode.title()} episode has {length} steps and return {score:.1f}.')\n",
    "  logger.scalar(f'{mode}_return', score)\n",
    "  logger.scalar(f'{mode}_length', length)\n",
    "  logger.scalar(f'{mode}_episodes', len(cache))\n",
    "  if mode == 'eval' or config.expl_gifs:\n",
    "    logger.video(f'{mode}_policy', video[None])\n",
    "  logger.write()\n",
    "\n",
    "def make_env(config, logger, mode, train_eps, eval_eps):\n",
    "  suite, task = config.task.split('_', 1)\n",
    "  if suite == 'dmc':\n",
    "    env = wrappers.DeepMindControl(task, config.action_repeat, config.size)\n",
    "    env = wrappers.NormalizeActions(env)\n",
    "  elif suite == 'atari':\n",
    "    env = wrappers.Atari(\n",
    "        task, config.action_repeat, config.size,\n",
    "        grayscale=config.grayscale,\n",
    "        life_done=False and ('train' in mode),\n",
    "        sticky_actions=True,\n",
    "        all_actions=True)\n",
    "    env = wrappers.OneHotAction(env)\n",
    "  elif suite == 'dmlab':\n",
    "    env = wrappers.DeepMindLabyrinth(\n",
    "        task,\n",
    "        mode if 'train' in mode else 'test',\n",
    "        config.action_repeat)\n",
    "    env = wrappers.OneHotAction(env)\n",
    "  else:\n",
    "    raise NotImplementedError(suite)\n",
    "  env = wrappers.TimeLimit(env, config.time_limit)\n",
    "  env = wrappers.SelectAction(env, key='action')\n",
    "  if (mode == 'train') or (mode == 'eval'):\n",
    "    callbacks = [functools.partial(\n",
    "        process_episode, config, logger, mode, train_eps, eval_eps)]\n",
    "    env = wrappers.CollectDataset(env, callbacks)\n",
    "  env = wrappers.RewardObs(env)\n",
    "  return env\n",
    "\n",
    "make = lambda mode: make_env(config, logger, mode, train_eps, eval_eps)\n",
    "train_envs = [make('train') for _ in range(config.envs)]\n",
    "acts = train_envs[0].action_space\n",
    "config.num_actions = acts.n if hasattr(acts, 'n') else acts.shape[0]\n",
    "\n",
    "class Dreamer(nn.Module):\n",
    "  def __init__(self, config, logger, dataset):\n",
    "    super(Dreamer, self).__init__()\n",
    "    self._config = config\n",
    "    self._logger = logger\n",
    "    self._should_log = tools.Every(config.log_every)\n",
    "    self._should_train = tools.Every(config.train_every)\n",
    "    self._should_pretrain = tools.Once()\n",
    "    self._should_reset = tools.Every(config.reset_every)\n",
    "    self._should_expl = tools.Until(int(\n",
    "        config.expl_until / config.action_repeat))\n",
    "    self._metrics = {}\n",
    "    self._step = count_steps(config.traindir)\n",
    "    # Schedules.\n",
    "    config.actor_entropy = (\n",
    "        lambda x=config.actor_entropy: tools.schedule(x, self._step))\n",
    "    config.actor_state_entropy = (\n",
    "        lambda x=config.actor_state_entropy: tools.schedule(x, self._step))\n",
    "    config.imag_gradient_mix = (\n",
    "        lambda x=config.imag_gradient_mix: tools.schedule(x, self._step))\n",
    "    self._dataset = dataset\n",
    "    self._wm = models.WorldModel(self._step, config)\n",
    "    self._task_behavior = models.ImagBehavior(\n",
    "        config, self._wm, config.behavior_stop_grad)\n",
    "    reward = lambda f, s, a: self._wm.heads['reward'](f).mean\n",
    "    self._expl_behavior = dict(\n",
    "        greedy=lambda: self._task_behavior,\n",
    "        random=lambda: expl.Random(config),\n",
    "        plan2explore=lambda: expl.Plan2Explore(config, self._wm, reward),\n",
    "    )[config.expl_behavior]()\n",
    "\n",
    "  def __call__(self, obs, reset, state=None, reward=None, training=True):\n",
    "    step = self._step\n",
    "    if self._should_reset(step):\n",
    "      state = None\n",
    "    if state is not None and reset.any():\n",
    "      mask = 1 - reset\n",
    "      for key in state[0].keys():\n",
    "        for i in range(state[0][key].shape[0]):\n",
    "          state[0][key][i] *= mask[i]\n",
    "      for i in range(len(state[1])):\n",
    "        state[1][i] *= mask[i]\n",
    "    if training and self._should_train(step):\n",
    "      steps = (\n",
    "          self._config.pretrain if self._should_pretrain()\n",
    "          else self._config.train_steps)\n",
    "      for _ in range(steps):\n",
    "        self._train(next(self._dataset))\n",
    "      if self._should_log(step):\n",
    "        for name, values in self._metrics.items():\n",
    "          self._logger.scalar(name, float(np.mean(values)))\n",
    "          self._metrics[name] = []\n",
    "        openl = self._wm.video_pred(next(self._dataset))\n",
    "        self._logger.video('train_openl', to_np(openl))\n",
    "        self._logger.write(fps=True)\n",
    "\n",
    "    policy_output, state = self._policy(obs, state, training)\n",
    "\n",
    "    if training:\n",
    "      self._step += len(reset)\n",
    "      self._logger.step = self._config.action_repeat * self._step\n",
    "    return policy_output, state\n",
    "\n",
    "  def _policy(self, obs, state, training):\n",
    "    if state is None:\n",
    "      batch_size = len(obs['image'])\n",
    "      latent = self._wm.dynamics.initial(len(obs['image']))\n",
    "      action = torch.zeros((batch_size, self._config.num_actions)).to(self._config.device)\n",
    "    else:\n",
    "      latent, action = state\n",
    "    embed = self._wm.encoder(self._wm.preprocess(obs))\n",
    "    latent, _ = self._wm.dynamics.obs_step(\n",
    "        latent, action, embed, self._config.collect_dyn_sample)\n",
    "    if self._config.eval_state_mean:\n",
    "      latent['stoch'] = latent['mean']\n",
    "    feat = self._wm.dynamics.get_feat(latent)\n",
    "    if not training:\n",
    "      actor = self._task_behavior.actor(feat)\n",
    "      action = actor.mode()\n",
    "    elif self._should_expl(self._step):\n",
    "      actor = self._expl_behavior.actor(feat)\n",
    "      action = actor.sample()\n",
    "    else:\n",
    "      actor = self._task_behavior.actor(feat)\n",
    "      action = actor.sample()\n",
    "    logprob = actor.log_prob(action)\n",
    "    latent = {k: v.detach()  for k, v in latent.items()}\n",
    "    action = action.detach()\n",
    "    if self._config.actor_dist == 'onehot_gumble':\n",
    "      action = torch.one_hot(torch.argmax(action, dim=-1), self._config.num_actions)\n",
    "    action = self._exploration(action, training)\n",
    "    policy_output = {'action': action, 'logprob': logprob}\n",
    "    state = (latent, action)\n",
    "    return policy_output, state\n",
    "\n",
    "  def _exploration(self, action, training):\n",
    "    amount = self._config.expl_amount if training else self._config.eval_noise\n",
    "    if amount == 0:\n",
    "      return action\n",
    "    if 'onehot' in self._config.actor_dist:\n",
    "      probs = amount / self._config.num_actions + (1 - amount) * action\n",
    "      return tools.OneHotDist(probs=probs).sample()\n",
    "    else:\n",
    "      return torch.clip(torchd.normal.Normal(action, amount).sample(), -1, 1)\n",
    "    raise NotImplementedError(self._config.action_noise)\n",
    "\n",
    "  def _train(self, data):\n",
    "    metrics = {}\n",
    "    post, context, mets = self._wm._train(data)\n",
    "    metrics.update(mets)\n",
    "    start = post\n",
    "    if self._config.pred_discount:  # Last step could be terminal.\n",
    "      start = {k: v[:, :-1] for k, v in post.items()}\n",
    "      context = {k: v[:, :-1] for k, v in context.items()}\n",
    "    reward = lambda f, s, a: self._wm.heads['reward'](\n",
    "        self._wm.dynamics.get_feat(s)).mode()\n",
    "    metrics.update(self._task_behavior._train(start, reward)[-1])\n",
    "    if self._config.expl_behavior != 'greedy':\n",
    "      if self._config.pred_discount:\n",
    "        data = {k: v[:, :-1] for k, v in data.items()}\n",
    "      mets = self._expl_behavior.train(start, context, data)[-1]\n",
    "      metrics.update({'expl_' + key: value for key, value in mets.items()})\n",
    "    for name, value in metrics.items():\n",
    "      if not name in self._metrics.keys():\n",
    "        self._metrics[name] = [value]\n",
    "      else:\n",
    "        self._metrics[name].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a67ad92-76dd-4d70-9084-c28f1f3e228c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dreamer(\n",
       "  (_wm): WorldModel(\n",
       "    (encoder): ConvEncoder(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "        (7): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (dynamics): RSSM(\n",
       "      (_inp_layers): Sequential(\n",
       "        (0): Linear(in_features=56, out_features=200, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (_cell): GRUCell(\n",
       "        (_layer): Linear(in_features=400, out_features=600, bias=True)\n",
       "      )\n",
       "      (_img_out_layers): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (_obs_out_layers): Sequential(\n",
       "        (0): Linear(in_features=1224, out_features=200, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (_ims_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "      (_obs_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "    )\n",
       "    (heads): ModuleDict(\n",
       "      (image): ConvDecoder(\n",
       "        (_linear_layer): Linear(in_features=250, out_features=1024, bias=True)\n",
       "        (_cnnt_layers): Sequential(\n",
       "          (0): ConvTranspose2d(1024, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "          (3): ELU(alpha=1.0)\n",
       "          (4): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2))\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): ConvTranspose2d(32, 3, kernel_size=(6, 6), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (reward): DenseHead(\n",
       "        (_mean_layers): Sequential(\n",
       "          (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "          (3): ELU(alpha=1.0)\n",
       "          (4): Linear(in_features=400, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_task_behavior): ImagBehavior(\n",
       "    (_world_model): WorldModel(\n",
       "      (encoder): ConvEncoder(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (3): ELU(alpha=1.0)\n",
       "          (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (7): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (dynamics): RSSM(\n",
       "        (_inp_layers): Sequential(\n",
       "          (0): Linear(in_features=56, out_features=200, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (_cell): GRUCell(\n",
       "          (_layer): Linear(in_features=400, out_features=600, bias=True)\n",
       "        )\n",
       "        (_img_out_layers): Sequential(\n",
       "          (0): Linear(in_features=200, out_features=200, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (_obs_out_layers): Sequential(\n",
       "          (0): Linear(in_features=1224, out_features=200, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (_ims_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (_obs_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "      )\n",
       "      (heads): ModuleDict(\n",
       "        (image): ConvDecoder(\n",
       "          (_linear_layer): Linear(in_features=250, out_features=1024, bias=True)\n",
       "          (_cnnt_layers): Sequential(\n",
       "            (0): ConvTranspose2d(1024, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "            (1): ELU(alpha=1.0)\n",
       "            (2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "            (3): ELU(alpha=1.0)\n",
       "            (4): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2))\n",
       "            (5): ELU(alpha=1.0)\n",
       "            (6): ConvTranspose2d(32, 3, kernel_size=(6, 6), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (reward): DenseHead(\n",
       "          (_mean_layers): Sequential(\n",
       "            (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "            (1): ELU(alpha=1.0)\n",
       "            (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "            (3): ELU(alpha=1.0)\n",
       "            (4): Linear(in_features=400, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (actor): ActionHead(\n",
       "      (_pre_layers): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (7): ELU(alpha=1.0)\n",
       "      )\n",
       "      (_dist_layer): Linear(in_features=400, out_features=12, bias=True)\n",
       "    )\n",
       "    (value): DenseHead(\n",
       "      (_mean_layers): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_slow_value): DenseHead(\n",
       "      (_mean_layers): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_expl_behavior): ImagBehavior(\n",
       "    (_world_model): WorldModel(\n",
       "      (encoder): ConvEncoder(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (3): ELU(alpha=1.0)\n",
       "          (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (5): ELU(alpha=1.0)\n",
       "          (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "          (7): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (dynamics): RSSM(\n",
       "        (_inp_layers): Sequential(\n",
       "          (0): Linear(in_features=56, out_features=200, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (_cell): GRUCell(\n",
       "          (_layer): Linear(in_features=400, out_features=600, bias=True)\n",
       "        )\n",
       "        (_img_out_layers): Sequential(\n",
       "          (0): Linear(in_features=200, out_features=200, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (_obs_out_layers): Sequential(\n",
       "          (0): Linear(in_features=1224, out_features=200, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (_ims_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (_obs_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "      )\n",
       "      (heads): ModuleDict(\n",
       "        (image): ConvDecoder(\n",
       "          (_linear_layer): Linear(in_features=250, out_features=1024, bias=True)\n",
       "          (_cnnt_layers): Sequential(\n",
       "            (0): ConvTranspose2d(1024, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "            (1): ELU(alpha=1.0)\n",
       "            (2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "            (3): ELU(alpha=1.0)\n",
       "            (4): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2))\n",
       "            (5): ELU(alpha=1.0)\n",
       "            (6): ConvTranspose2d(32, 3, kernel_size=(6, 6), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "        (reward): DenseHead(\n",
       "          (_mean_layers): Sequential(\n",
       "            (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "            (1): ELU(alpha=1.0)\n",
       "            (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "            (3): ELU(alpha=1.0)\n",
       "            (4): Linear(in_features=400, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (actor): ActionHead(\n",
       "      (_pre_layers): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (7): ELU(alpha=1.0)\n",
       "      )\n",
       "      (_dist_layer): Linear(in_features=400, out_features=12, bias=True)\n",
       "    )\n",
       "    (value): DenseHead(\n",
       "      (_mean_layers): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_slow_value): DenseHead(\n",
       "      (_mean_layers): Sequential(\n",
       "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ELU(alpha=1.0)\n",
       "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Dreamer(config, logger, train_dataset).to(config.device)\n",
    "agent.requires_grad_(requires_grad=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0fa4d02-fc29-4930-b3d8-1921c6bb76ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dreamer(\n",
      "  (_wm): WorldModel(\n",
      "    (encoder): ConvEncoder(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
      "        (7): ELU(alpha=1.0)\n",
      "      )\n",
      "    )\n",
      "    (dynamics): RSSM(\n",
      "      (_inp_layers): Sequential(\n",
      "        (0): Linear(in_features=56, out_features=200, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "      )\n",
      "      (_cell): GRUCell(\n",
      "        (_layer): Linear(in_features=400, out_features=600, bias=True)\n",
      "      )\n",
      "      (_img_out_layers): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "      )\n",
      "      (_obs_out_layers): Sequential(\n",
      "        (0): Linear(in_features=1224, out_features=200, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "      )\n",
      "      (_ims_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
      "      (_obs_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
      "    )\n",
      "    (heads): ModuleDict(\n",
      "      (image): ConvDecoder(\n",
      "        (_linear_layer): Linear(in_features=250, out_features=1024, bias=True)\n",
      "        (_cnnt_layers): Sequential(\n",
      "          (0): ConvTranspose2d(1024, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "          (1): ELU(alpha=1.0)\n",
      "          (2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "          (3): ELU(alpha=1.0)\n",
      "          (4): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2))\n",
      "          (5): ELU(alpha=1.0)\n",
      "          (6): ConvTranspose2d(32, 3, kernel_size=(6, 6), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (reward): DenseHead(\n",
      "        (_mean_layers): Sequential(\n",
      "          (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "          (1): ELU(alpha=1.0)\n",
      "          (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "          (3): ELU(alpha=1.0)\n",
      "          (4): Linear(in_features=400, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_task_behavior): ImagBehavior(\n",
      "    (_world_model): WorldModel(\n",
      "      (encoder): ConvEncoder(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (1): ELU(alpha=1.0)\n",
      "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (3): ELU(alpha=1.0)\n",
      "          (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (5): ELU(alpha=1.0)\n",
      "          (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (7): ELU(alpha=1.0)\n",
      "        )\n",
      "      )\n",
      "      (dynamics): RSSM(\n",
      "        (_inp_layers): Sequential(\n",
      "          (0): Linear(in_features=56, out_features=200, bias=True)\n",
      "          (1): ELU(alpha=1.0)\n",
      "        )\n",
      "        (_cell): GRUCell(\n",
      "          (_layer): Linear(in_features=400, out_features=600, bias=True)\n",
      "        )\n",
      "        (_img_out_layers): Sequential(\n",
      "          (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (1): ELU(alpha=1.0)\n",
      "        )\n",
      "        (_obs_out_layers): Sequential(\n",
      "          (0): Linear(in_features=1224, out_features=200, bias=True)\n",
      "          (1): ELU(alpha=1.0)\n",
      "        )\n",
      "        (_ims_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (_obs_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
      "      )\n",
      "      (heads): ModuleDict(\n",
      "        (image): ConvDecoder(\n",
      "          (_linear_layer): Linear(in_features=250, out_features=1024, bias=True)\n",
      "          (_cnnt_layers): Sequential(\n",
      "            (0): ConvTranspose2d(1024, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "            (3): ELU(alpha=1.0)\n",
      "            (4): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2))\n",
      "            (5): ELU(alpha=1.0)\n",
      "            (6): ConvTranspose2d(32, 3, kernel_size=(6, 6), stride=(2, 2))\n",
      "          )\n",
      "        )\n",
      "        (reward): DenseHead(\n",
      "          (_mean_layers): Sequential(\n",
      "            (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "            (3): ELU(alpha=1.0)\n",
      "            (4): Linear(in_features=400, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (actor): ActionHead(\n",
      "      (_pre_layers): Sequential(\n",
      "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (7): ELU(alpha=1.0)\n",
      "      )\n",
      "      (_dist_layer): Linear(in_features=400, out_features=12, bias=True)\n",
      "    )\n",
      "    (value): DenseHead(\n",
      "      (_mean_layers): Sequential(\n",
      "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (_slow_value): DenseHead(\n",
      "      (_mean_layers): Sequential(\n",
      "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_expl_behavior): ImagBehavior(\n",
      "    (_world_model): WorldModel(\n",
      "      (encoder): ConvEncoder(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (1): ELU(alpha=1.0)\n",
      "          (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (3): ELU(alpha=1.0)\n",
      "          (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (5): ELU(alpha=1.0)\n",
      "          (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
      "          (7): ELU(alpha=1.0)\n",
      "        )\n",
      "      )\n",
      "      (dynamics): RSSM(\n",
      "        (_inp_layers): Sequential(\n",
      "          (0): Linear(in_features=56, out_features=200, bias=True)\n",
      "          (1): ELU(alpha=1.0)\n",
      "        )\n",
      "        (_cell): GRUCell(\n",
      "          (_layer): Linear(in_features=400, out_features=600, bias=True)\n",
      "        )\n",
      "        (_img_out_layers): Sequential(\n",
      "          (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (1): ELU(alpha=1.0)\n",
      "        )\n",
      "        (_obs_out_layers): Sequential(\n",
      "          (0): Linear(in_features=1224, out_features=200, bias=True)\n",
      "          (1): ELU(alpha=1.0)\n",
      "        )\n",
      "        (_ims_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (_obs_stat_layer): Linear(in_features=200, out_features=100, bias=True)\n",
      "      )\n",
      "      (heads): ModuleDict(\n",
      "        (image): ConvDecoder(\n",
      "          (_linear_layer): Linear(in_features=250, out_features=1024, bias=True)\n",
      "          (_cnnt_layers): Sequential(\n",
      "            (0): ConvTranspose2d(1024, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "            (3): ELU(alpha=1.0)\n",
      "            (4): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2))\n",
      "            (5): ELU(alpha=1.0)\n",
      "            (6): ConvTranspose2d(32, 3, kernel_size=(6, 6), stride=(2, 2))\n",
      "          )\n",
      "        )\n",
      "        (reward): DenseHead(\n",
      "          (_mean_layers): Sequential(\n",
      "            (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "            (1): ELU(alpha=1.0)\n",
      "            (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "            (3): ELU(alpha=1.0)\n",
      "            (4): Linear(in_features=400, out_features=1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (actor): ActionHead(\n",
      "      (_pre_layers): Sequential(\n",
      "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (7): ELU(alpha=1.0)\n",
      "      )\n",
      "      (_dist_layer): Linear(in_features=400, out_features=12, bias=True)\n",
      "    )\n",
      "    (value): DenseHead(\n",
      "      (_mean_layers): Sequential(\n",
      "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (_slow_value): DenseHead(\n",
      "      (_mean_layers): Sequential(\n",
      "        (0): Linear(in_features=250, out_features=400, bias=True)\n",
      "        (1): ELU(alpha=1.0)\n",
      "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (3): ELU(alpha=1.0)\n",
      "        (4): Linear(in_features=400, out_features=400, bias=True)\n",
      "        (5): ELU(alpha=1.0)\n",
      "        (6): Linear(in_features=400, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008b30d-af21-4b91-9ff2-238634d5ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This need to be run once for train_dataset to initialize\n",
    "prefill = max(0, config.prefill - count_steps(config.traindir))\n",
    "print(f'Prefill dataset ({prefill} steps).')\n",
    "if hasattr(acts, 'discrete'):\n",
    "  random_actor = tools.OneHotDist(torch.zeros_like(torch.Tensor(acts.low))[None])\n",
    "else:\n",
    "  random_actor = torchd.independent.Independent(\n",
    "      torchd.uniform.Uniform(torch.Tensor(acts.low)[None],\n",
    "                             torch.Tensor(acts.high)[None]), 1)\n",
    "def random_agent(o, d, s, r):\n",
    "  action = random_actor.sample()\n",
    "  logprob = random_actor.log_prob(action)\n",
    "  return {'action': action, 'logprob': logprob}, None\n",
    "tools.simulate(random_agent, train_envs, prefill)\n",
    "logger.step = config.action_repeat * count_steps(config.traindir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10a722-0ecb-4df8-b806-ef9cda4a7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_dataset))\n",
    "random_sample = next(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65084b-2f2b-4d41-a1c5-18e05a230f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(random_sample))\n",
    "print(random_sample.keys())\n",
    "for key in random_sample.keys():\n",
    "    print(f\"Now looking at {key}\")\n",
    "    print(type(random_sample[key]))\n",
    "    print(random_sample[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57296185-2bd9-439b-aa17-56c10ac3ddec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f9536c-d3b3-408f-a1ad-54e4a327736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import WorldModel\n",
    "wm = WorldModel(step, config).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aceff4ba-a5a2-4430-90b1-8e704ae9f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_input = {\n",
    "        'orientations': torch.tensor(np.random.randn(50, 50, 14), dtype=torch.float32),  # 方向数据，正态分布\n",
    "        'height': torch.tensor(np.random.rand(50, 50), dtype=torch.float32),  # 高度数据，均匀分布\n",
    "        'velocity': torch.tensor(np.random.randn(50, 50, 9), dtype=torch.float32),  # 速度数据，正态分布\n",
    "        'image': torch.tensor(np.random.rand(50, 50, 64, 64, 3), dtype=torch.float32),  # 图像数据，均匀分布\n",
    "        'reward': torch.tensor(np.random.randn(50, 50), dtype=torch.float32),  # 奖励数据，正态分布\n",
    "        'discount': torch.tensor(np.random.rand(50, 50), dtype=torch.float32),  # 折扣数据，均匀分布\n",
    "        'action': torch.tensor(np.random.randn(50, 50, 6), dtype=torch.float32),  # 动作数据，正态分布\n",
    "        'logprob': torch.tensor(np.random.randn(50, 50), dtype=torch.float32)  # 对数概率，正态分布\n",
    "    }\n",
    "for key in trial_input:\n",
    "    trial_input[key] = trial_input[key].to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cdec6b9-eb3f-494c-bcb9-b68041503ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['orientations', 'height', 'velocity', 'image', 'reward', 'discount', 'action', 'logprob'])\n",
      "Now looking at orientations\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50, 14])\n",
      "Now looking at height\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50])\n",
      "Now looking at velocity\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50, 9])\n",
      "Now looking at image\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50, 64, 64, 3])\n",
      "Now looking at reward\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50])\n",
      "Now looking at discount\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50])\n",
      "Now looking at action\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50, 6])\n",
      "Now looking at logprob\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 50])\n"
     ]
    }
   ],
   "source": [
    "print(type(trial_input))\n",
    "print(trial_input.keys())\n",
    "for key in trial_input.keys():\n",
    "    print(f\"Now looking at {key}\")\n",
    "    print(type(trial_input[key]))\n",
    "    print(trial_input[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd857c5f-d804-49d0-8b5d-bd38a858a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'wm' is on device: cuda:0\n",
      "Tensor 'orientations' is on device: cuda:0\n",
      "Tensor 'height' is on device: cuda:0\n",
      "Tensor 'velocity' is on device: cuda:0\n",
      "Tensor 'image' is on device: cuda:0\n",
      "Tensor 'reward' is on device: cuda:0\n",
      "Tensor 'discount' is on device: cuda:0\n",
      "Tensor 'action' is on device: cuda:0\n",
      "Tensor 'logprob' is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 检查模型的设备位置\n",
    "device = next(wm.parameters()).device\n",
    "print(f\"Model 'wm' is on device: {device}\")\n",
    "\n",
    "# 检查trial_input中每个张量的设备位置\n",
    "for key, tensor in trial_input.items():\n",
    "    print(f\"Tensor '{key}' is on device: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc5d11f-307e-4cfa-bc17-2b382ed34bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/xthu/dreamer-torch/models.py:100: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  obs['image'] = torch.Tensor(obs['image']) / 255.0 - 0.5\n",
      "/ssd/xthu/dreamer-torch/models.py:104: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  obs['reward'] = torch.Tensor(obs['reward']).unsqueeze(-1)\n",
      "/ssd/xthu/dreamer-torch/models.py:109: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  obs['discount'] = torch.Tensor(obs['discount']).unsqueeze(-1)\n",
      "/ssd/xthu/dreamer-torch/models.py:110: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  obs = {k: torch.Tensor(v).to(self._config.device) for k, v in obs.items()}\n",
      "/home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/jit/_trace.py:958: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%eps.2 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%849, %857, %858) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.4 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%1057, %1065, %1066) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.6 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%1273, %1281, %1282) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.8 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%1489, %1497, %1498) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.10 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%1705, %1713, %1714) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.11 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%2196, %2204, %2205) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.12 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%2319, %2327, %2328) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.13 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%2446, %2454, %2455) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.14 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%2573, %2581, %2582) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.15 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%2700, %2708, %2709) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.16 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%2827, %2835, %2836) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.17 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%2954, %2962, %2963) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.18 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3081, %3089, %3090) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.19 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3208, %3216, %3217) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.20 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3335, %3343, %3344) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.21 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3462, %3470, %3471) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.22 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3589, %3597, %3598) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.23 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3716, %3724, %3725) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.24 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3843, %3851, %3852) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "\t%eps.25 : Float(6, 50, strides=[50, 1], requires_grad=0, device=cuda:0) = aten::normal(%3970, %3978, %3979) # /home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/distributions/utils.py:46:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "/home/xthu/anaconda3/envs/dreamer/lib/python3.8/site-packages/torch/jit/_trace.py:958: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "With rtol=1e-05 and atol=1e-05, found 7351272 element(s) (out of 11059200) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.10083290934562683 (0.3911789357662201 vs. 0.4920118451118469), which occurred at index (1, 40, 97, 37, 2).\n",
      "  _check_trace(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('model_research/origin_model')\n",
    "writer.add_graph(wm, trial_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4ee88-e277-44e6-bb2b-07bc8c20b2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e2399-8be4-433f-bcb5-90128950a6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
